{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runing on PyMC3 v3.3\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pymc3 as pm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pystan\n",
    "import pystan.chains\n",
    "from collections import OrderedDict\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "print('Runing on PyMC3 v{}'.format(pm.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = '/usr/local/lib/python3.5/dist-packages/pystan/tests/data/blocker.1.csv'\n",
    "f2 = '/usr/local/lib/python3.5/dist-packages/pystan/tests/data/blocker.2.csv'\n",
    "\n",
    "# f1 = '/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pystan/tests/data/blocker.1.csv'\n",
    "# f2 = '/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/pystan/tests/data/blocker.2.csv'\n",
    "\n",
    "# read csv using numpy\n",
    "c1 = np.loadtxt(f1, skiprows=41, delimiter=',')[:, 4:]\n",
    "c1_colnames = open(f1, 'r').readlines()[36].strip().split(',')[4:]\n",
    "np.testing.assert_equal(c1_colnames[0], 'd')\n",
    "c2 = np.loadtxt(f2, skiprows=41, delimiter=',')[:, 4:]\n",
    "c2_colnames = open(f2, 'r').readlines()[36].strip().split(',')[4:]\n",
    "np.testing.assert_equal(c1_colnames, c2_colnames)\n",
    "np.testing.assert_equal(len(c1_colnames), c1.shape[1])\n",
    "\n",
    "n_samples = len(c1)\n",
    "np.testing.assert_equal(n_samples, 1000)\n",
    "\n",
    "c1 = OrderedDict((k, v) for k, v in zip(c1_colnames, c1.T))\n",
    "c2 = OrderedDict((k, v) for k, v in zip(c2_colnames, c2.T))\n",
    "\n",
    "lst = dict(fnames_oi=c1_colnames, samples=[{'chains': c1}, {'chains': c2}],\n",
    "           n_save=np.repeat(n_samples, 2), permutation=None,\n",
    "           warmup=0, warmup2=[0, 0], chains=2, n_flatnames=len(c1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['d', 'sigmasq_delta', 'mu.1', 'mu.2', 'mu.3', 'mu.4', 'mu.5', 'mu.6', 'mu.7', 'mu.8', 'mu.9', 'mu.10', 'mu.11', 'mu.12', 'mu.13', 'mu.14', 'mu.15', 'mu.16', 'mu.17', 'mu.18', 'mu.19', 'mu.20', 'mu.21', 'mu.22', 'delta.1', 'delta.2', 'delta.3', 'delta.4', 'delta.5', 'delta.6', 'delta.7', 'delta.8', 'delta.9', 'delta.10', 'delta.11', 'delta.12', 'delta.13', 'delta.14', 'delta.15', 'delta.16', 'delta.17', 'delta.18', 'delta.19', 'delta.20', 'delta.21', 'delta.22', 'delta_new', 'sigma_delta'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slst = lst['samples'][0]['chains']\n",
    "slst.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = list(slst.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = lst['chains']\n",
    "\n",
    "ns_save = lst['n_save']\n",
    "ns_warmup2 = lst['warmup2']\n",
    "ns_kept = [s - w for s, w in zip(lst['n_save'], lst['warmup2'])]\n",
    "\n",
    "n_samples = min(ns_kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eff = [\n",
    "    466.099, 136.953, 1170.390, 541.256,\n",
    "    518.051, 589.244, 764.813, 688.294,\n",
    "    323.777, 502.892, 353.823, 588.142,\n",
    "    654.336, 480.914, 176.978, 182.649,\n",
    "    642.389, 470.949, 561.947, 581.187,\n",
    "    446.389, 397.641, 338.511, 678.772,\n",
    "    1442.250, 837.956, 869.865, 951.124,\n",
    "    619.336, 875.805, 233.260, 786.568,\n",
    "    910.144, 231.582, 907.666, 747.347,\n",
    "    720.660, 195.195, 944.547, 767.271,\n",
    "    723.665, 1077.030, 470.903, 954.924,\n",
    "    497.338, 583.539, 697.204, 98.421\n",
    "]\n",
    "\n",
    "ess = []\n",
    "for i in range(len(n_eff)):\n",
    "    ess.append(pystan.chains.ess(lst, i))\n",
    "    np.testing.assert_almost_equal(ess[i], n_eff[i], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymc3.util import get_default_varnames\n",
    "from pymc3.backends.base import MultiTrace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import fftconvolve\n",
    "\n",
    "\n",
    "def autocorr(x, lag=None):\n",
    "    \"\"\"\n",
    "    Compute autocorrelation using FFT for every lag for the input array\n",
    "    https://en.wikipedia.org/wiki/Autocorrelation#Efficient_computation\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : Numpy array\n",
    "        An array containing MCMC samples\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    acorr: Numpy array same size as the input array\n",
    "    \"\"\"\n",
    "    y = x - x.mean()\n",
    "    n = len(y)\n",
    "    result = fftconvolve(y, y[::-1])\n",
    "    acorr = result[len(result) // 2:]\n",
    "    acorr /= np.arange(n, 0, -1)\n",
    "    acorr /= acorr[0]\n",
    "    if lag is None:\n",
    "        return acorr\n",
    "    else:\n",
    "        warnings.warn(\n",
    "            \"The `lag` argument has been deprecated. If you want to get \"\n",
    "            \"the value of a specific lag please call `autocorr(x)[lag]`.\",\n",
    "            DeprecationWarning)\n",
    "        return acorr[lag]\n",
    "\n",
    "\n",
    "def autocov(x, lag=None):\n",
    "    \"\"\"Compute autocovariance estimates for every lag for the input array\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : Numpy array\n",
    "        An array containing MCMC samples\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    acov: Numpy array same size as the input array\n",
    "    \"\"\"\n",
    "    acorr = autocorr(x)\n",
    "    varx = np.var(x, ddof=1) * (len(x) - 1) / len(x)\n",
    "    acov = acorr * varx\n",
    "    if lag is None:\n",
    "        return acov\n",
    "    else:\n",
    "        warnings.warn(\n",
    "            \"The `lag` argument has been deprecated. If you want to get \"\n",
    "            \"the value of a specific lag please call `autocov(x)[lag]`.\",\n",
    "            DeprecationWarning)\n",
    "        return acov[lag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_n(mtrace, varnames=None, include_transformed=False):\n",
    "    R\"\"\"Returns estimate of the effective sample size of a set of traces.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mtrace : MultiTrace or trace object\n",
    "      A MultiTrace object containing parallel traces (minimum 2)\n",
    "      of one or more stochastic parameters.\n",
    "    varnames : list\n",
    "      Names of variables to include in the effective_n report\n",
    "    include_transformed : bool\n",
    "      Flag for reporting automatically transformed variables in addition\n",
    "      to original variables (defaults to False).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    n_eff : dictionary of floats (MultiTrace) or float (trace object)\n",
    "        Return the effective sample size, :math:`\\hat{n}_{eff}`\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The diagnostic is computed by:\n",
    "\n",
    "    .. math:: \\hat{n}_{eff} = \\frac{mn}{1 + 2 \\sum_{t=1}^T \\hat{\\rho}_t}\n",
    "\n",
    "    where :math:`\\hat{\\rho}_t` is the estimated autocorrelation at lag t, and T\n",
    "    is the first odd positive integer for which the sum\n",
    "    :math:`\\hat{\\rho}_{T+1} + \\hat{\\rho}_{T+1}` is negative.\n",
    "\n",
    "    The current implementation is similar to Stan, which uses Geyer's initial\n",
    "    monotone sequence criterion (Geyer, 1992; Geyer, 2011).\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Gelman et al. BDA (2014)\"\"\"\n",
    "\n",
    "    def get_neff(x):\n",
    "        \"\"\"Compute the effective sample size for a 2D array\n",
    "        \"\"\"\n",
    "        trace_value = x.T\n",
    "        nchain, n_samples = trace_value.shape\n",
    "\n",
    "        acov = np.asarray([autocov(trace_value[chain])\n",
    "                           for chain in range(nchain)])\n",
    "\n",
    "        chain_mean = trace_value.mean(axis=1)\n",
    "        chain_var = acov[:, 0] * n_samples / (n_samples - 1.)\n",
    "        acov_t = acov[:, 1] * n_samples / (n_samples - 1.)\n",
    "        mean_var = np.mean(chain_var)\n",
    "        var_plus = mean_var * (n_samples - 1.) / n_samples\n",
    "        var_plus += np.var(chain_mean, ddof=1)\n",
    "\n",
    "        rho_hat_t = np.zeros(n_samples)\n",
    "        rho_hat_even = 1.\n",
    "        rho_hat_t[0] = rho_hat_even\n",
    "        rho_hat_odd = 1. - (mean_var - np.mean(acov_t)) / var_plus\n",
    "        rho_hat_t[1] = rho_hat_odd\n",
    "        # Geyer's initial positive sequence\n",
    "        max_t = 1\n",
    "        t = 1\n",
    "        while t < (n_samples - 2) and (rho_hat_even + rho_hat_odd) >= 0.:\n",
    "            rho_hat_even = 1. - (mean_var - np.mean(acov[:, t + 1])) / var_plus\n",
    "            rho_hat_odd = 1. - (mean_var - np.mean(acov[:, t + 2])) / var_plus\n",
    "            if (rho_hat_even + rho_hat_odd) >= 0:\n",
    "                rho_hat_t[t + 1] = rho_hat_even\n",
    "                rho_hat_t[t + 2] = rho_hat_odd\n",
    "            max_t = t + 2\n",
    "            t += 2\n",
    "\n",
    "        # Geyer's initial monotone sequence\n",
    "        t = 3\n",
    "        while t <= max_t - 2:\n",
    "            if (rho_hat_t[t + 1] + rho_hat_t[t + 2]) > (rho_hat_t[t - 1] + rho_hat_t[t]):\n",
    "                rho_hat_t[t + 1] = (rho_hat_t[t - 1] + rho_hat_t[t]) / 2.\n",
    "                rho_hat_t[t + 2] = rho_hat_t[t + 1]\n",
    "            t += 2\n",
    "        ess = nchain * n_samples\n",
    "        ess = ess / (-1. + 2. * np.sum(rho_hat_t))\n",
    "        return ess\n",
    "\n",
    "    def generate_neff(trace_values):\n",
    "        x = np.array(trace_values)\n",
    "        shape = x.shape\n",
    "\n",
    "        # Make sure to handle scalars correctly, adding extra dimensions if\n",
    "        # needed. We could use np.squeeze here, but we don't want to squeeze\n",
    "        # out dummy dimensions that a user inputs.\n",
    "        if len(shape) == 2:\n",
    "            x = np.atleast_3d(trace_values)\n",
    "\n",
    "        # Transpose all dimensions, which makes the loop below\n",
    "        # easier by moving the axes of the variable to the front instead\n",
    "        # of the chain and sample axes.\n",
    "        x = x.transpose()\n",
    "\n",
    "        # Get an array the same shape as the var\n",
    "        _n_eff = np.zeros(x.shape[:-2])\n",
    "\n",
    "        # Iterate over tuples of indices of the shape of var\n",
    "        for tup in np.ndindex(*list(x.shape[:-2])):\n",
    "            _n_eff[tup] = get_neff(x[tup])\n",
    "\n",
    "        if len(shape) == 2:\n",
    "            return _n_eff[0]\n",
    "\n",
    "        return np.transpose(_n_eff)\n",
    "\n",
    "    if not isinstance(mtrace, MultiTrace):\n",
    "        # Return neff for non-multitrace array\n",
    "        return generate_neff(mtrace)\n",
    "\n",
    "    if mtrace.nchains < 2:\n",
    "        raise ValueError(\n",
    "            'Calculation of effective sample size requires multiple chains '\n",
    "            'of the same length.')\n",
    "\n",
    "    if varnames is None:\n",
    "        varnames = get_default_varnames(\n",
    "            mtrace.varnames, include_transformed=include_transformed)\n",
    "\n",
    "    n_eff = {}\n",
    "\n",
    "    for var in varnames:\n",
    "        n_eff[var] = generate_neff(mtrace.get_values(var, combine=False))\n",
    "\n",
    "    return n_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess2 = []\n",
    "for i, varname in enumerate(param_names):\n",
    "    trace_values = [lst['samples'][im]['chains'][varname] for im in range(m)]\n",
    "    ess2.append(effective_n(trace_values))\n",
    "    np.testing.assert_almost_equal(ess2[i], n_eff[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>PyStan</th>\n",
       "      <th>PyMC3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>466.099</td>\n",
       "      <td>466.098810</td>\n",
       "      <td>465.994306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136.953</td>\n",
       "      <td>136.952532</td>\n",
       "      <td>136.941283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1170.390</td>\n",
       "      <td>1170.393732</td>\n",
       "      <td>1170.222485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>541.256</td>\n",
       "      <td>541.255659</td>\n",
       "      <td>541.199238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518.051</td>\n",
       "      <td>518.051325</td>\n",
       "      <td>517.996363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>589.244</td>\n",
       "      <td>589.243546</td>\n",
       "      <td>589.163026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>764.813</td>\n",
       "      <td>764.812721</td>\n",
       "      <td>764.667763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>688.294</td>\n",
       "      <td>688.293542</td>\n",
       "      <td>688.212347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>323.777</td>\n",
       "      <td>323.777181</td>\n",
       "      <td>323.743779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>502.892</td>\n",
       "      <td>502.891905</td>\n",
       "      <td>502.837470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>353.823</td>\n",
       "      <td>353.822729</td>\n",
       "      <td>353.793908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>588.142</td>\n",
       "      <td>588.141518</td>\n",
       "      <td>588.045040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>654.336</td>\n",
       "      <td>654.335742</td>\n",
       "      <td>654.216984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>480.914</td>\n",
       "      <td>480.914331</td>\n",
       "      <td>480.857175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>176.978</td>\n",
       "      <td>176.977626</td>\n",
       "      <td>176.966982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>182.649</td>\n",
       "      <td>182.648542</td>\n",
       "      <td>182.634739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>642.389</td>\n",
       "      <td>642.389260</td>\n",
       "      <td>642.278555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>470.949</td>\n",
       "      <td>470.949244</td>\n",
       "      <td>470.894658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>561.947</td>\n",
       "      <td>561.946880</td>\n",
       "      <td>561.868481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>581.187</td>\n",
       "      <td>581.186630</td>\n",
       "      <td>581.129337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>446.389</td>\n",
       "      <td>446.389238</td>\n",
       "      <td>446.333580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>397.641</td>\n",
       "      <td>397.641095</td>\n",
       "      <td>397.597217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>338.511</td>\n",
       "      <td>338.510536</td>\n",
       "      <td>338.485896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>678.772</td>\n",
       "      <td>678.771523</td>\n",
       "      <td>678.661293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1442.250</td>\n",
       "      <td>1442.252440</td>\n",
       "      <td>1442.042092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>837.956</td>\n",
       "      <td>837.955698</td>\n",
       "      <td>837.849683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>869.865</td>\n",
       "      <td>869.865497</td>\n",
       "      <td>869.710633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>951.124</td>\n",
       "      <td>951.123727</td>\n",
       "      <td>950.933339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>619.336</td>\n",
       "      <td>619.336051</td>\n",
       "      <td>619.243131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>875.805</td>\n",
       "      <td>875.804964</td>\n",
       "      <td>875.695420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>233.260</td>\n",
       "      <td>233.260458</td>\n",
       "      <td>233.239514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>786.568</td>\n",
       "      <td>786.567760</td>\n",
       "      <td>786.463445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>910.144</td>\n",
       "      <td>910.143753</td>\n",
       "      <td>909.931239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>231.582</td>\n",
       "      <td>231.581848</td>\n",
       "      <td>231.564143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>907.666</td>\n",
       "      <td>907.665813</td>\n",
       "      <td>907.518937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>747.347</td>\n",
       "      <td>747.346732</td>\n",
       "      <td>747.212315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>720.660</td>\n",
       "      <td>720.660283</td>\n",
       "      <td>720.555130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>195.195</td>\n",
       "      <td>195.195121</td>\n",
       "      <td>195.176669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>944.547</td>\n",
       "      <td>944.546821</td>\n",
       "      <td>944.371209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>767.271</td>\n",
       "      <td>767.270590</td>\n",
       "      <td>767.143768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>723.665</td>\n",
       "      <td>723.664570</td>\n",
       "      <td>723.559907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1077.030</td>\n",
       "      <td>1077.025450</td>\n",
       "      <td>1076.857749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>470.903</td>\n",
       "      <td>470.902902</td>\n",
       "      <td>470.832818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>954.924</td>\n",
       "      <td>954.924046</td>\n",
       "      <td>954.748152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>497.338</td>\n",
       "      <td>497.338153</td>\n",
       "      <td>497.289064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>583.539</td>\n",
       "      <td>583.538694</td>\n",
       "      <td>583.446292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>697.204</td>\n",
       "      <td>697.204057</td>\n",
       "      <td>697.077568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>98.421</td>\n",
       "      <td>98.421158</td>\n",
       "      <td>98.414273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target       PyStan        PyMC3\n",
       "0    466.099   466.098810   465.994306\n",
       "1    136.953   136.952532   136.941283\n",
       "2   1170.390  1170.393732  1170.222485\n",
       "3    541.256   541.255659   541.199238\n",
       "4    518.051   518.051325   517.996363\n",
       "5    589.244   589.243546   589.163026\n",
       "6    764.813   764.812721   764.667763\n",
       "7    688.294   688.293542   688.212347\n",
       "8    323.777   323.777181   323.743779\n",
       "9    502.892   502.891905   502.837470\n",
       "10   353.823   353.822729   353.793908\n",
       "11   588.142   588.141518   588.045040\n",
       "12   654.336   654.335742   654.216984\n",
       "13   480.914   480.914331   480.857175\n",
       "14   176.978   176.977626   176.966982\n",
       "15   182.649   182.648542   182.634739\n",
       "16   642.389   642.389260   642.278555\n",
       "17   470.949   470.949244   470.894658\n",
       "18   561.947   561.946880   561.868481\n",
       "19   581.187   581.186630   581.129337\n",
       "20   446.389   446.389238   446.333580\n",
       "21   397.641   397.641095   397.597217\n",
       "22   338.511   338.510536   338.485896\n",
       "23   678.772   678.771523   678.661293\n",
       "24  1442.250  1442.252440  1442.042092\n",
       "25   837.956   837.955698   837.849683\n",
       "26   869.865   869.865497   869.710633\n",
       "27   951.124   951.123727   950.933339\n",
       "28   619.336   619.336051   619.243131\n",
       "29   875.805   875.804964   875.695420\n",
       "30   233.260   233.260458   233.239514\n",
       "31   786.568   786.567760   786.463445\n",
       "32   910.144   910.143753   909.931239\n",
       "33   231.582   231.581848   231.564143\n",
       "34   907.666   907.665813   907.518937\n",
       "35   747.347   747.346732   747.212315\n",
       "36   720.660   720.660283   720.555130\n",
       "37   195.195   195.195121   195.176669\n",
       "38   944.547   944.546821   944.371209\n",
       "39   767.271   767.270590   767.143768\n",
       "40   723.665   723.664570   723.559907\n",
       "41  1077.030  1077.025450  1076.857749\n",
       "42   470.903   470.902902   470.832818\n",
       "43   954.924   954.924046   954.748152\n",
       "44   497.338   497.338153   497.289064\n",
       "45   583.539   583.538694   583.446292\n",
       "46   697.204   697.204057   697.077568\n",
       "47    98.421    98.421158    98.414273"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neff = pd.DataFrame(data=dict(Target=n_eff, PyStan=ess, PyMC3=ess2),\n",
    "                       columns=['Target', 'PyStan', 'PyMC3'])\n",
    "df_neff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "960 µs ± 7.29 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pm.effective_n(trace_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "776 µs ± 3.17 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit effective_n(trace_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_values2 = [np.random.randn(10000) for im in range(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.99 ms ± 57.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit pm.effective_n(trace_values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.6 ms ± 867 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit effective_n(trace_values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.9 ms ± 812 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit effective_n2(trace_values2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "ess2 = []\n",
    "for i, varname in enumerate(param_names):\n",
    "    trace_values = [lst['samples'][im]['chains'][varname] for im in range(m)]\n",
    "    ess2.append(effective_n2(trace_values))\n",
    "    np.testing.assert_almost_equal(ess2[i], n_eff[i], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True)\n",
    "def mult_conj(a):\n",
    "    \"\"\"Multiply a with conj(a) and store in a.\n",
    "    \n",
    "    [Re, Re, Im, Re, Im...]\n",
    "    like output from scipy.fftpack.rfft\n",
    "    \"\"\"\n",
    "    n = len(a)\n",
    "    if n == 0:\n",
    "        return\n",
    "    a[0] = a[0] * a[0]\n",
    "    for i in range(1, (n + 1) // 2):\n",
    "        j, k = 2 * i - 1, 2 * i\n",
    "        a[j] = a[j] * a[j] + a[k] * a[k]\n",
    "        a[k] = 0\n",
    "    if n > 1 and n % 2 == 0:\n",
    "        a[n - 1] = a[n - 1] * a[n - 1]\n",
    "\n",
    "        \n",
    "@numba.jit\n",
    "def autocov2(x):\n",
    "    assert len(x.shape) == 2\n",
    "    y = x - np.mean(x, axis=-1, keepdims=True)\n",
    "    n = y.shape[-1]\n",
    "    shape = 2 * n - 1\n",
    "    \n",
    "    fft_len = fftpack.next_fast_len(shape)\n",
    "    fx = fftpack.rfft(y, fft_len, overwrite_x=False)\n",
    "    for i in range(x.shape[0]):\n",
    "        mult_conj(fx[i, :])\n",
    "    out = fftpack.irfft(fx, fft_len, overwrite_x=False)\n",
    "    out = out[..., :n]\n",
    "    out[:] /= np.arange(n, 0, -1)\n",
    "    return out\n",
    "\n",
    "\n",
    "@numba.jit(nopython=True)\n",
    "def get_neff_inner(trace_value, acov):\n",
    "    \"\"\"Compute the effective sample size for a 2D array\n",
    "    \"\"\"\n",
    "    n_chains, n_samples = trace_value.shape\n",
    "    assert acov.shape == (n_chains, n_samples)\n",
    "\n",
    "    chain_mean = np.sum(trace_value, 1) / n_samples\n",
    "\n",
    "    chain_var = acov[:, 0] * n_samples / (n_samples - 1.)\n",
    "    acov_t = acov[:, 1] * n_samples / (n_samples - 1.)\n",
    "    mean_var = np.mean(chain_var)\n",
    "    var_plus = mean_var * (n_samples - 1.) / n_samples\n",
    "    var_plus += np.var(chain_mean) * n_chains / (n_chains - 1.)\n",
    "\n",
    "    rho_hat_t = np.zeros(n_samples)\n",
    "    rho_hat_even = 1.\n",
    "    rho_hat_t[0] = rho_hat_even\n",
    "    rho_hat_odd = 1. - (mean_var - np.mean(acov_t)) / var_plus\n",
    "    rho_hat_t[1] = rho_hat_odd\n",
    "    max_t = 1\n",
    "    t = 1\n",
    "\n",
    "    acov_means = np.sum(acov, 0) / n_chains\n",
    "    while t < (n_samples - 2) and (rho_hat_even + rho_hat_odd) >= 0.:\n",
    "        rho_hat_even = 1. - (mean_var - acov_means[t + 1]) / var_plus\n",
    "        rho_hat_odd = 1. - (mean_var - acov_means[t + 2]) / var_plus\n",
    "        if (rho_hat_even + rho_hat_odd) >= 0:\n",
    "            rho_hat_t[t + 1] = rho_hat_even\n",
    "            rho_hat_t[t + 2] = rho_hat_odd\n",
    "        max_t = t + 2\n",
    "        t += 2\n",
    "\n",
    "    t = 3\n",
    "    while t <= max_t - 2:\n",
    "        if (rho_hat_t[t + 1] + rho_hat_t[t + 2]) > (rho_hat_t[t - 1] + rho_hat_t[t]):\n",
    "            rho_hat_t[t + 1] = (rho_hat_t[t - 1] + rho_hat_t[t]) / 2.\n",
    "            rho_hat_t[t + 2] = rho_hat_t[t + 1]\n",
    "        t += 2\n",
    "    ess = nchain * n_samples\n",
    "    ess = ess / (-1. + 2. * np.sum(rho_hat_t))\n",
    "    return ess\n",
    "\n",
    "\n",
    "@numba.jit()\n",
    "def get_neff2(x):\n",
    "    \"\"\"Compute the effective sample size for a 2D array\n",
    "    \"\"\"\n",
    "    neff = np.zeros(x.shape[0])\n",
    "    nvals, nchain, n_samples = x.shape\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        trace_value = x[i]\n",
    "        nchain, n_samples = trace_value.shape\n",
    "        acov = autocov2(trace_value)\n",
    "        neff[i] = get_neff_inner(trace_value, acov)\n",
    "    return neff\n",
    "\n",
    "\n",
    "def effective_n2(mtrace, varnames=None, include_transformed=False):\n",
    "    def generate_neff(trace_values):\n",
    "        \"\"\"Trace values is an array (*varshape, n_chains, n_samples)\"\"\"\n",
    "        x = np.stack([val.T for val in trace_values], axis=-2)\n",
    "        *varshape, n_chains, n_samples = x.shape\n",
    "        x = np.ascontiguousarray(x.reshape((-1, n_chains, n_samples)))\n",
    "        return get_neff2(x).reshape(varshape)\n",
    "\n",
    "    if not isinstance(mtrace, pm.backends.base.MultiTrace):\n",
    "        # Return neff for non-multitrace array\n",
    "        return generate_neff(mtrace)\n",
    "\n",
    "    if mtrace.nchains < 2:\n",
    "        raise ValueError(\n",
    "            'Calculation of effective sample size requires multiple chains '\n",
    "            'of the same length.')\n",
    "\n",
    "    if varnames is None:\n",
    "        varnames = pm.util.get_default_varnames(mtrace.varnames,include_transformed=include_transformed)\n",
    "\n",
    "    n_eff = {}\n",
    "\n",
    "    for var in varnames:\n",
    "        n_eff[var] = generate_neff(mtrace.get_values(var, combine=False))\n",
    "\n",
    "    return n_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effective_n2(mtrace, varnames=None, include_transformed=False):\n",
    "    R\"\"\"Returns estimate of the effective sample size of a set of traces.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mtrace : MultiTrace or trace object\n",
    "      A MultiTrace object containing parallel traces (minimum 2)\n",
    "      of one or more stochastic parameters.\n",
    "    varnames : list\n",
    "      Names of variables to include in the effective_n report\n",
    "    include_transformed : bool\n",
    "      Flag for reporting automatically transformed variables in addition\n",
    "      to original variables (defaults to False).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    n_eff : dictionary of floats (MultiTrace) or float (trace object)\n",
    "        Return the effective sample size, :math:`\\hat{n}_{eff}`\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The diagnostic is computed by:\n",
    "\n",
    "    .. math:: \\hat{n}_{eff} = \\frac{mn}{1 + 2 \\sum_{t=1}^T \\hat{\\rho}_t}\n",
    "\n",
    "    where :math:`\\hat{\\rho}_t` is the estimated autocorrelation at lag t, and T\n",
    "    is the first odd positive integer for which the sum\n",
    "    :math:`\\hat{\\rho}_{T+1} + \\hat{\\rho}_{T+1}` is negative.\n",
    "\n",
    "    The current implementation is similar to Stan, which uses Geyer's initial\n",
    "    monotone sequence criterion (Geyer, 1992; Geyer, 2011).\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    Gelman et al. BDA (2014)\"\"\"\n",
    "\n",
    "    def get_neff(x):\n",
    "        \"\"\"Compute the effective sample size for a 2D array\n",
    "        \"\"\"\n",
    "        trace_value = x.T\n",
    "        nchain, n_samples = trace_value.shape\n",
    "\n",
    "        acov = np.asarray([autocov(trace_value[chain])\n",
    "                           for chain in range(nchain)])\n",
    "\n",
    "        chain_mean = trace_value.mean(axis=1)\n",
    "        chain_var = acov[:, 0] * n_samples / (n_samples - 1.)\n",
    "        acov_t = acov[:, 1] * n_samples / (n_samples - 1.)\n",
    "        mean_var = np.mean(chain_var)\n",
    "        var_plus = mean_var * (n_samples - 1.) / n_samples\n",
    "        var_plus += np.var(chain_mean, ddof=1)\n",
    "\n",
    "        rho_hat_t = np.zeros(n_samples)\n",
    "        rho_hat_t[0] = 1.\n",
    "        rho_hat_t[1] = 1. - (mean_var - np.mean(acov_t)) / var_plus\n",
    "        # Geyer's initial positive sequence\n",
    "        rho_hat_tmp = 1. - (mean_var - np.mean(acov, axis=0)) / var_plus\n",
    "        t_ = np.where((rho_hat_tmp[2::2] + rho_hat_tmp[3::2]) < 0)[0][0]\n",
    "        max_t = 2*t_+2\n",
    "        rho_hat_t[2:max_t] = rho_hat_tmp[2:max_t]\n",
    "\n",
    "        # Geyer's initial monotone sequence\n",
    "        t = 3\n",
    "        while t <= max_t - 2:\n",
    "            if (rho_hat_t[t + 1] + rho_hat_t[t + 2]) > (rho_hat_t[t - 1] + rho_hat_t[t]):\n",
    "                rho_hat_t[t + 1] = (rho_hat_t[t - 1] + rho_hat_t[t]) / 2.\n",
    "                rho_hat_t[t + 2] = rho_hat_t[t + 1]\n",
    "            t += 2\n",
    "        ess = nchain * n_samples\n",
    "        ess = ess / (-1. + 2. * np.sum(rho_hat_t))\n",
    "        return ess\n",
    "\n",
    "    def generate_neff(trace_values):\n",
    "        x = np.array(trace_values)\n",
    "        shape = x.shape\n",
    "\n",
    "        # Make sure to handle scalars correctly, adding extra dimensions if\n",
    "        # needed. We could use np.squeeze here, but we don't want to squeeze\n",
    "        # out dummy dimensions that a user inputs.\n",
    "        if len(shape) == 2:\n",
    "            x = np.atleast_3d(trace_values)\n",
    "\n",
    "        # Transpose all dimensions, which makes the loop below\n",
    "        # easier by moving the axes of the variable to the front instead\n",
    "        # of the chain and sample axes.\n",
    "        x = x.transpose()\n",
    "\n",
    "        # Get an array the same shape as the var\n",
    "        _n_eff = np.zeros(x.shape[:-2])\n",
    "\n",
    "        # Iterate over tuples of indices of the shape of var\n",
    "        for tup in np.ndindex(*list(x.shape[:-2])):\n",
    "            _n_eff[tup] = get_neff(x[tup])\n",
    "\n",
    "        if len(shape) == 2:\n",
    "            return _n_eff[0]\n",
    "\n",
    "        return np.transpose(_n_eff)\n",
    "\n",
    "    if not isinstance(mtrace, MultiTrace):\n",
    "        # Return neff for non-multitrace array\n",
    "        return generate_neff(mtrace)\n",
    "\n",
    "    if mtrace.nchains < 2:\n",
    "        raise ValueError(\n",
    "            'Calculation of effective sample size requires multiple chains '\n",
    "            'of the same length.')\n",
    "\n",
    "    if varnames is None:\n",
    "        varnames = get_default_varnames(\n",
    "            mtrace.varnames, include_transformed=include_transformed)\n",
    "\n",
    "    n_eff = {}\n",
    "\n",
    "    for var in varnames:\n",
    "        n_eff[var] = generate_neff(mtrace.get_values(var, combine=False))\n",
    "\n",
    "    return n_eff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
