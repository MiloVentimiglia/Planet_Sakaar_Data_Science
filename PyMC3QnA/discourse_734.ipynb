{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discourse.pymc.io/t/custom-theano-op-to-do-numerical-integration/734/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as tt\n",
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "theano.config.compute_test_value = 'off'\n",
    "\n",
    "class Integrate(theano.Op):\n",
    "    def __init__(self, expr, var, *extra_vars):\n",
    "        super().__init__()\n",
    "        self._expr = expr\n",
    "        self._var = var\n",
    "        self._extra_vars = extra_vars\n",
    "        self._func = theano.function(\n",
    "            [var] + list(extra_vars),\n",
    "            self._expr,\n",
    "            on_unused_input='ignore')\n",
    "    \n",
    "    def make_node(self, start, stop, *extra_vars):\n",
    "        self._extra_vars_node = extra_vars\n",
    "        assert len(self._extra_vars) == len(extra_vars)\n",
    "        self._start = start\n",
    "        self._stop = stop\n",
    "        vars = [start, stop] + list(extra_vars)\n",
    "        return theano.Apply(self, vars, [tt.dscalar().type()])\n",
    "    \n",
    "    def perform(self, node, inputs, out):\n",
    "        start, stop, *args = inputs\n",
    "        val = quad(self._func, start, stop, args=tuple(args))[0]\n",
    "        out[0][0] = np.array(val)\n",
    "        \n",
    "    def grad(self, inputs, grads):\n",
    "        start, stop, *args = inputs\n",
    "        out, = grads\n",
    "        replace = dict(zip(self._extra_vars, args))\n",
    "        \n",
    "        replace_ = replace.copy()\n",
    "        replace_[self._var] = start\n",
    "        dstart = out * theano.clone(-self._expr, replace=replace_)\n",
    "        \n",
    "        replace_ = replace.copy()\n",
    "        replace_[self._var] = stop\n",
    "        dstop = out * theano.clone(self._expr, replace=replace_)\n",
    "\n",
    "        grads = tt.grad(self._expr, self._extra_vars)\n",
    "        dargs = []\n",
    "        for grad in grads:\n",
    "            integrate = Integrate(grad, self._var, self._extra_vars)\n",
    "            darg = out * integrate(start, stop, *args)\n",
    "            dargs.append(darg)\n",
    "            \n",
    "        return [dstart, dstop] + dargs\n",
    "\n",
    "    \n",
    "## Basic usage\n",
    "\n",
    "# We define the function we want to integrate\n",
    "x = tt.dscalar('x')\n",
    "x.tag.test_value = np.zeros(())\n",
    "a = tt.dscalar('a')\n",
    "a.tag.test_value = np.ones(())\n",
    "\n",
    "func = a ** 2 * x**2\n",
    "integrate = Integrate(func, x, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check gradients\n",
    "from theano.tests.unittest_tools import verify_grad\n",
    "verify_grad(integrate, (np.array(0.), np.array(1.), np.array(2.)))\n",
    "verify_grad(integrate, (np.array(-2.), np.array(5.), np.array(8.)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1.33333333)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, we define values for the integral\n",
    "start = tt.dscalar('start')\n",
    "start.tag.test_value = np.zeros(())\n",
    "stop = tt.dscalar('stop')\n",
    "stop.tag.test_value = np.ones(())\n",
    "a_ = tt.dscalar('a_')\n",
    "a_.tag.test_value = np.ones(())\n",
    "\n",
    "# Note, that a_ != a\n",
    "val = integrate(start, stop, a_)\n",
    "\n",
    "# Evaluate the integral and derivatives\n",
    "val.eval({start: 0., stop: 1., a_: 2.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(12.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.grad(val, a_).eval({start: -2, stop: 1, a_: 2.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-4.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.grad(val, start).eval({start: 1., stop: 2., a_: 2.})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [a, stop, start]\n",
      "Sampling 2 chains: 100%|██████████| 2000/2000 [00:33<00:00, 59.81draws/s]\n",
      "The acceptance probability does not match the target. It is 0.8818877503630203, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "import pymc3 as pm\n",
    "\n",
    "## Usage in PyMC3\n",
    "with pm.Model() as model:\n",
    "    start = pm.Normal('start', -5, 1)\n",
    "    stop = pm.Normal('stop', 5, 1)\n",
    "    a = pm.Normal('a', 0.5, 1)\n",
    "    \n",
    "    # Define the function to integrate in plain theano\n",
    "    x = tt.dscalar('x_')\n",
    "    x.tag.test_value = np.zeros(())\n",
    "    a_ = tt.dscalar('a_')\n",
    "    a_.tag.test_value = np.ones(())\n",
    "\n",
    "    func = a_ ** 2 * x**2\n",
    "    integrate = Integrate(func, x, a_)\n",
    "\n",
    "    # Now we plug in the values from the model.\n",
    "    # The `a_` from above corresponds to the `a` here.\n",
    "    val = integrate(start, stop, a)\n",
    "    pm.Normal('y', mu=val, sd=1, observed=10)\n",
    "    mtrace = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = np.asarray([[ 2.700e+00,  2.700e+00,  2.800e+00,  3.100e+00,  3.300e+00,\n",
    "         3.500e+00,  3.700e+00,  3.800e+00,  3.900e+00,  3.900e+00,\n",
    "         4.500e+00,  4.600e+00,  4.900e+00,  5.100e+00,  5.200e+00,\n",
    "         5.900e+00,  6.000e+00,  6.200e+00,  6.400e+00,  6.700e+00,\n",
    "         7.000e+00,  7.100e+00,  7.400e+00,  7.400e+00,  7.500e+00,\n",
    "         7.500e+00,  8.400e+00,  9.200e+00,  9.400e+00,  9.600e+00,\n",
    "         1.020e+01,  1.040e+01,  1.040e+01,  1.200e+01,  1.200e+01,\n",
    "         1.280e+01,  1.440e+01,  1.470e+01,  1.580e+01,  1.630e+01,\n",
    "         1.660e+01,  1.790e+01,  1.840e+01,  1.860e+01,  1.880e+01,\n",
    "         2.120e+01,  2.140e+01,  2.140e+01,  2.530e+01,  2.590e+01,\n",
    "         2.690e+01,  2.940e+01,  2.980e+01,  3.450e+01,  3.500e+01,\n",
    "         3.840e+01,  3.850e+01,  4.100e+01,  9.570e+01],\n",
    "       [ 1.090e+02,  8.000e+00,  0.000e+00, -2.000e-01,  2.000e+01,\n",
    "         2.080e+02, -9.000e-01,  6.000e+01, -1.810e+02,  0.000e+00,\n",
    "        -2.100e+01, -5.300e+01,  1.720e+02, -4.000e+01, -1.900e+01,\n",
    "        -5.800e+01,  1.800e+01, -3.130e+02, -3.100e+01,  3.000e+00,\n",
    "         1.500e+02,  1.400e+01,  1.700e+01,  4.900e+01,  3.000e-01,\n",
    "         6.000e-01,  2.790e+02,  1.720e+02,  5.500e+01,  7.000e+01,\n",
    "        -9.900e+01, -7.400e+01,  4.600e+01,  2.000e+00,  1.600e+01,\n",
    "        -3.050e+02, -5.000e-01, -1.100e+00, -5.800e+01,  2.540e+02,\n",
    "         1.860e+02, -6.650e+01, -1.060e+02, -1.100e+01,  9.300e+01,\n",
    "        -8.000e-01,  1.530e+02,  5.700e+01, -9.740e+01, -1.177e+02,\n",
    "         1.924e+02, -2.281e+02,  2.260e+01, -1.035e+02, -1.044e+02,\n",
    "         1.478e+02, -1.852e+02, -1.952e+02, -2.470e+02]])\n",
    "\n",
    "rn = data_[0]\n",
    "vn = data_[1]\n",
    "G = 4.302*10**-6\n",
    "rmin = 3.0\n",
    "R = 95.7\n",
    "gamma=3.77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [beta, M]\n",
      "Sampling 2 chains: 100%|██████████| 2000/2000 [03:30<00:00,  7.37draws/s]\n",
      "The acceptance probability does not match the target. It is 0.9076947795115683, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    }
   ],
   "source": [
    "start = theano.shared(-(np.pi)/2)\n",
    "stop = theano.shared((np.pi)/2)\n",
    "\n",
    "\n",
    "with pm.Model() as basic_model:\n",
    "    M = pm.Uniform('M', lower=10**8, upper=10**13)\n",
    "    beta = pm.Uniform('beta', lower=2.001, upper=2.999, testval=2.5)\n",
    "    \n",
    "    # set up the integration function\n",
    "    x = tt.dscalar('x')\n",
    "    x.tag.test_value = np.zeros(())\n",
    "    beta_ = tt.dscalar('beta_')\n",
    "    beta_.tag.test_value = np.ones(())*2.5\n",
    "    z1 = tt.cos(x)**(2*((gamma/(beta_ - 2)) - 3/2) + 3)\n",
    "    integrate = Integrate(z1, x, beta_)\n",
    "    integ_val = integrate(start, stop, beta)\n",
    "    # integ = tt.printing.Print('integ')(integ_val)\n",
    "    \n",
    "    # define the logp\n",
    "    def logp_func(rn, vn):\n",
    "        q = (gamma/(beta - 2)) - 3/2\n",
    "        B = (G*M) / ((beta -2 )*(R**(3 - beta)))\n",
    "        K = (gamma - 3) / ((rmin**(3 - gamma)) * (2*B)**0.5) * integ_val\n",
    "        logp = - tt.log(K*((1 -((1/(2*B))*((vn**2)*rn**(beta - \n",
    "                                           2))))**(q+1))*(rn**(1-gamma +(beta/2))))\n",
    "        return tt.sum(logp)\n",
    "    \n",
    "    logpvar = pm.DensityDist(\"logpvar\", logp_func, observed={\"rn\": rn, \"vn\":vn})\n",
    "    trace = pm.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://discourse.pymc.io/t/pymc3-using-a-parameter-as-a-limit-of-integral/1447/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(100)\n",
    "y_obs = np.random.randn(100)\n",
    "\n",
    "start = theano.shared(0.)\n",
    "with pm.Model() as basic_model:\n",
    "    a = pm.Uniform('a', 0.01, 0.1)\n",
    "    b = pm.Uniform('b', 0.001, 0.01)\n",
    "    xp = pm.Normal('xp', mu=x, sd=a + b * x, shape=100)\n",
    "\n",
    "    t = tt.dscalar('t')\n",
    "    t.tag.test_value = np.zeros(())\n",
    "    func = (1 + 0.2 * ((1 + t)**3. - 1))**(-0.5)\n",
    "    integrate = Integrate(func, t)\n",
    "    \n",
    "    mu = tt.stack([integrate(start, xp[i]) for i in range(100)])\n",
    "\n",
    "    y = pm.Normal('y', mu=mu, sd=0.5, observed=y_obs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
