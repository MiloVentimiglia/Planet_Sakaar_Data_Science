{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc3 as pm\n",
    "from pymc3.distributions import Interpolated\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def from_posterior(param, samples):\n",
    "    smin, smax = np.min(samples), np.max(samples)\n",
    "    width = smax - smin\n",
    "    x = np.linspace(smin, smax, 100)\n",
    "    y = stats.gaussian_kde(samples)(x)\n",
    "\n",
    "    x = np.concatenate([[x[0] - 3 * width], x, [x[-1] + 3 * width]])\n",
    "    y = np.concatenate([[0], y, [0]])\n",
    "    return Interpolated(param, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize random number generator\n",
    "np.random.seed(123)\n",
    "\n",
    "# Target values\n",
    "t = [38.095, 13.346, 30.106, 13.353]\n",
    "\n",
    "# Users' precision in term of sigma\n",
    "s = [0.01, 0.05, 0.03, 0.12]\n",
    "\n",
    "# Number of measures for each target\n",
    "n_measures = 10\n",
    "\n",
    "# Simulate some data\n",
    "measures = []\n",
    "for i in range(0, 4):\n",
    "    y1 = t[i] + np.random.randn(n_measures) * s[0]\n",
    "    y2 = t[i] + np.random.randn(n_measures) * s[1]\n",
    "    y3 = t[i] + np.random.randn(n_measures) * s[2]\n",
    "    y4 = t[i] + np.random.randn(n_measures) * s[3]\n",
    "    x = np.array([y1, y2, y3, y4])\n",
    "    measures.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [sigma4_log__, sigma3_log__, sigma2_log__, sigma1_log__, rho_log__, mu]\n",
      "100%|██████████| 1500/1500 [00:23<00:00, 64.08it/s] \n",
      "The acceptance probability does not match the target. It is 0.9522403790083452, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9583093119784403, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as hierachical_model:\n",
    "    # Latent mean and sigma, I want to estimate these parameters\n",
    "    mu = pm.Normal('mu', 0., 100.)\n",
    "    rho = pm.HalfNormal('rho', 10.)\n",
    "\n",
    "    sigma1 = pm.HalfNormal('sigma1', rho)\n",
    "    sigma2 = pm.HalfNormal('sigma2', rho)\n",
    "    sigma3 = pm.HalfNormal('sigma3', rho)\n",
    "    sigma4 = pm.HalfNormal('sigma4', rho)\n",
    "\n",
    "    like1 = pm.Normal('like1', mu, sigma1, observed=measures[0][0])\n",
    "    like2 = pm.Normal('like2', mu, sigma2, observed=measures[0][1])\n",
    "    like3 = pm.Normal('like3', mu, sigma3, observed=measures[0][2])\n",
    "    like4 = pm.Normal('like4', mu, sigma4, observed=measures[0][3])\n",
    "\n",
    "    trace = pm.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [sigma4_interval__, sigma3_interval__, sigma2_interval__, sigma1_interval__, mu]\n",
      "100%|██████████| 1500/1500 [01:18<00:00, 27.55it/s]\n",
      "The acceptance probability does not match the target. It is 0.9779216336696305, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The acceptance probability does not match the target. It is 0.9844412091908469, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [sigma4_interval__, sigma3_interval__, sigma2_interval__, sigma1_interval__, mu]\n",
      "100%|██████████| 1500/1500 [04:07<00:00,  2.73it/s]\n",
      "The acceptance probability does not match the target. It is 0.9997121841109345, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.9999765663758933, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "The gelman-rubin statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using adapt_diag...\n",
      "Multiprocess sampling (2 chains in 2 jobs)\n",
      "NUTS: [sigma4_interval__, sigma3_interval__, sigma2_interval__, sigma1_interval__, mu]\n",
      "100%|██████████| 1500/1500 [00:50<00:00, 29.76it/s]\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "for j in range(1,4):\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        # Latent mean and sigma, I want to estimate these parameters\n",
    "        mu = pm.Normal('mu', 0., 100.)\n",
    "\n",
    "        # Priors are posteriors from previous iteration\n",
    "        sigma1 = from_posterior('sigma1', trace['sigma1'])\n",
    "        sigma2 = from_posterior('sigma2', trace['sigma2'])\n",
    "        sigma3 = from_posterior('sigma3', trace['sigma3'])\n",
    "        sigma4 = from_posterior('sigma4', trace['sigma4'])\n",
    "    \n",
    "        like1 = pm.Normal('like1', mu, sigma1, observed=measures[j][0])\n",
    "        like2 = pm.Normal('like2', mu, sigma2, observed=measures[j][1])\n",
    "        like3 = pm.Normal('like3', mu, sigma3, observed=measures[j][2])\n",
    "        like4 = pm.Normal('like4', mu, sigma4, observed=measures[j][3])\n",
    "        \n",
    "        trace = pm.sample(1000, init='adapt_diag')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
